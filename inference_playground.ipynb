{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1683dd62-1001-4be2-ab5a-d89965adf311",
   "metadata": {},
   "source": [
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/machinelearnear/vtoonify-in-studio-lab/blob/main/inference_playground.ipynb)\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/machinelearnear/vtoonify-in-studio-lab/blob/main/inference_playground.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9089e70-f655-43d6-a210-fb749dc2f74b",
   "metadata": {},
   "source": [
    "# Run `VToonify`\n",
    "- Original: https://github.com/williamyang1991/VToonify\n",
    "- Modified from [pixel2style2pixel](https://github.com/eladrich/pixel2style2pixel/blob/master/notebooks/inference_playground.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e088059-045c-49c6-9c7c-d522984a50ce",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "542f4d8c-7bb1-4375-a6b0-262455b54a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists as path_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf8a6a6b-c5e5-4458-816c-fb0d4780ec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "CODE_DIR = 'VToonify'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74a2a1ff-e79e-4e3f-b255-3d926a873939",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path_exists(CODE_DIR):\n",
    "    !git clone https://github.com/williamyang1991/VToonify.git $CODE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d1ee642-8927-4332-b6a1-50b232ca347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path_exists('ninja-linux.zip'):\n",
    "    !wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
    "    !sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
    "    !sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force \n",
    "\n",
    "try:\n",
    "    import wget\n",
    "except ImportError:\n",
    "    !pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7cad44f-25ab-48bd-b9c1-99c1362fbb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(f'./{CODE_DIR}')\n",
    "MODEL_DIR = os.path.join(os.path.dirname(os.getcwd()), CODE_DIR, 'checkpoint')\n",
    "DATA_DIR = os.path.join(os.path.dirname(os.getcwd()), CODE_DIR, 'data')\n",
    "OUT_DIR = os.path.join(os.path.dirname(os.getcwd()), CODE_DIR, 'output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54151247-e1bd-4a6a-9d18-cf8cefc5878f",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd24618c-3045-45c9-8e0d-fd056ccce98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cmake==3.21.0\n",
      "  Using cached cmake-3.21.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (19.8 MB)\n",
      "Installing collected packages: cmake\n",
      "Successfully installed cmake-3.21.0\n",
      "Collecting dlib==19.21.0\n",
      "  Using cached dlib-19.21.0.tar.gz (3.2 MB)\n",
      "Building wheels for collected packages: dlib\n",
      "  Building wheel for dlib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dlib: filename=dlib-19.21.0-cp38-cp38-linux_x86_64.whl size=4063007 sha256=7dc975dcad0627f6d619d3e31af696f96804e8a11829fc7a22dad84c02036cb4\n",
      "  Stored in directory: /home/studio-lab-user/.cache/pip/wheels/3a/4e/b6/77346839e430150a62d9b46bf7e0a37181fe01fd07d5d452a7\n",
      "Successfully built dlib\n",
      "Installing collected packages: dlib\n",
      "Successfully installed dlib-19.21.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import dlib\n",
    "except ImportError:\n",
    "    !pip install cmake==3.21.0\n",
    "    !pip install dlib==19.21.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35263d7f-9eb9-4e23-a440-c2596f7d496f",
   "metadata": {},
   "source": [
    "### Mount Drive and copy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9b76a2-febc-4c34-ade6-7acd03f4cafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "ROOT_FOLDER = \"vtoonify\" # @param {type:\"string\"}\n",
    "PROJECT_FOLDER = \"checkpoint\" # @param {type:\"string\"}\n",
    "MOUNTED_PATH = Path('/content/drive')\n",
    "MYDRIVE_PATH = MOUNTED_PATH / \"MyDrive\"\n",
    "PROJECT_PATH = MYDRIVE_PATH /  ROOT_FOLDER / PROJECT_FOLDER\n",
    "\n",
    "drive.mount(str(MOUNTED_PATH))\n",
    "\n",
    "os.makedirs(PROJECT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af736ea-dee0-454c-bbce-9949217990e5",
   "metadata": {},
   "source": [
    "Your checkpoint folder should contain the encoder.pt/faceparsing.pth files and the vtoonify_t_{xyz} checkpoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff3b49e-37a9-435a-a78c-2dbf8020ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r $PROJECT_PATH ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04553477-61f7-48b1-91b0-12fcb4f2115d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Style Transfer with `VToonify-D`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1ecf48-9924-4b99-ae52-911e272c35e0",
   "metadata": {},
   "source": [
    "Transfer a default cartoon style onto a default face image `./data/077436.jpg`:\n",
    "\n",
    "`python style_transfer.py --scale_image`\n",
    "\n",
    "The results are saved in the folder `./output/`, where `077436_input.jpg` is the rescaled input image to fit VToonify (this image can serve as the input without `--scale_image`) and `077436_vtoonify_d.jpg` is the result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48138851-29fc-43ff-8dae-2deddbfbfdb2",
   "metadata": {},
   "source": [
    "Specify the content image and the model, control the style with the following options:\n",
    "\n",
    "- `--content`: path to the target face image or video\n",
    "- `--style_id`: the index of the style image (find the mapping between index and the style image here).\n",
    "- `--style_degree` (default: 0.5): adjust the degree of style.\n",
    "- `--color_transfer` (default: False): perform color transfer if loading a VToonify-Dsdc model.\n",
    "- `--ckpt`: path of the VToonify-D model. By default, a VToonify-Dsd trained on cartoon style is loaded.\n",
    "- `--exstyle_path`: path of the extrinsic style code. By default, codes in the same directory as --ckpt are loaded.\n",
    "- `--scale_image`: rescale the input image/video to fit VToonify (highly recommend).\n",
    "- `--padding` (default: 200, 200, 200, 200): left, right, top, bottom paddings to the eye center.\n",
    "Here is an example of arcane style transfer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd66e96-eb3c-4813-bb0e-5f3ba7aa5146",
   "metadata": {},
   "source": [
    "**Style transfer for images**\n",
    "```sh\n",
    "python style_transfer.py --content ./data/038648.jpg \\\n",
    "       --scale_image --style_id 77 --style_degree 0.5 \\\n",
    "       --ckpt ./checkpoint/vtoonify_d_arcane/vtoonify_s_d.pt \\\n",
    "       --padding 600 600 600 600     # use large padding to avoid cropping the image\n",
    "```\n",
    "\n",
    "Specify `--video` to perform video toonification:\n",
    "\n",
    "```sh\n",
    "python style_transfer.py --scale_image --content ./data/YOUR_VIDEO.mp4 --video\n",
    "```\n",
    "\n",
    "The above style control options (`--style_id`, `--style_degree`, `--color_transfer`) also work for videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa24169a-c3b9-4c2b-b630-a5db35cf2dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cartoon026:      balanced \n",
    "# cartoon299:      big eyes \n",
    "# arcane000:       for female \n",
    "# arcane077:       for male \n",
    "# pixar052:                  \n",
    "# caricature039:   big mouth \n",
    "# caricature068:   balanced\n",
    "# style_type = \"cartoon026\" # [\"cartoon026\", \"cartoon299\", \"arcane000\", \"arcane077\", \"pixar052\", \"caricature039\", \"caricature068\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c640fc1-4dfa-4a71-b5da-d430d3bd87b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python style_transfer.py --scale_image --content ./data/YOUR_VIDEO.mp4 --video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0bc873-78ba-4fe4-98be-ff9fdddc33a7",
   "metadata": {},
   "source": [
    "## Style Transfer with `VToonify-T`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1182e0a-f6e3-4c12-95ae-33414da4a55d",
   "metadata": {},
   "source": [
    "Specify `--backbone` as ''toonify'' to load and use a VToonify-T model.\n",
    "\n",
    "```sh\n",
    "python style_transfer.py --content ./data/038648.jpg \\\n",
    "       --scale_image --backbone toonify \\\n",
    "       --ckpt ./checkpoint/vtoonify_t_arcane/vtoonify.pt \\\n",
    "       --padding 600 600 600 600     # use large padding to avoid cropping the image\n",
    "```\n",
    "\n",
    "In VToonify-T, `--style_id`, `--style_degree`, `--color_transfer`, `--exstyle_path` are not used.\n",
    "\n",
    "As with VToonify-D, specify `--video` to perform video toonification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae4e8d9-bbb3-4f03-b130-0f66d5330aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_type = \"arcane\" # [\"cartoon\", \"caricature\", \"arcane\", \"comic\", \"pixar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5601fb7b-dcc4-43e8-a031-f7ee40388bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pre-trained weights\n",
    "path = MODEL_PATHS_T[style_type]\n",
    "style_folder = os.path.join(MODEL_DIR, f'vtoonify_t_{style_type}')\n",
    "\n",
    "if not path_exists(style_folder):\n",
    "    os.makedirs(style_folder)\n",
    "download_command = get_download_model_command(file_id=path[\"id\"], file_name = os.path.join(f'vtoonify_t_{style_type}',path[\"name\"]))\n",
    "!{download_command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a7000f-5d23-4874-b75c-1c67d339c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python style_transfer.py --content ./data/input.mp4 \\\n",
    "       --scale_image --backbone toonify \\\n",
    "       --ckpt ./checkpoint/vtoonify_t_arcane/vtoonify.pt \\\n",
    "       --padding 600 600 600 600     # use large padding to avoid cropping the image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearnear-vtoonify-env:Python",
   "language": "python",
   "name": "conda-env-machinelearnear-vtoonify-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
